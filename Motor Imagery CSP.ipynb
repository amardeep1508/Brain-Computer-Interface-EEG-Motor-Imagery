{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "#import pymysql as db\n",
    "import os\n",
    "import sklearn\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "#from sshtunnel import SSHTunnelForwarder\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import classification_report, average_precision_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#BCI MNE Imports\n",
    "import mne\n",
    "from mne import Epochs, pick_types, find_events\n",
    "from mne.channels import read_layout\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting edf Parameters from C:\\648 wala\\VIVEK SHARMA\\EDUCATIONAL\\Brain Computer Interface\\DataSets\\Comptetion3\\k3b.gdf...\n",
      "GDF file detected\n",
      "Overlapping events detected. Use find_edf_events for the original events.\n",
      "Setting channel info structure...\n",
      "Interpolating stim channel. Events may jitter.\n",
      "Created Raw.info structure...\n",
      "Reading 0 ... 986779  =      0.000 ...  3947.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f4f567bb7e4c>:4: RuntimeWarning: Overlapping events detected. Use find_edf_events for the original events.\n",
      "  raw_files = [read_raw_edf('C:\\\\648 wala\\\\VIVEK SHARMA\\\\EDUCATIONAL\\\\Brain Computer Interface\\\\DataSets\\\\Comptetion3\\\\k3b.gdf', preload=True, stim_channel='auto')]\n",
      "<ipython-input-4-f4f567bb7e4c>:4: RuntimeWarning: Interpolating stim channel. Events may jitter.\n",
      "  raw_files = [read_raw_edf('C:\\\\648 wala\\\\VIVEK SHARMA\\\\EDUCATIONAL\\\\Brain Computer Interface\\\\DataSets\\\\Comptetion3\\\\k3b.gdf', preload=True, stim_channel='auto')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Data Ingestion\n",
    "\n",
    "raw_files = [read_raw_edf('C:\\\\648 wala\\\\VIVEK SHARMA\\\\EDUCATIONAL\\\\Brain Computer Interface\\\\DataSets\\\\Comptetion3\\\\k3b.gdf', preload=True, stim_channel='auto')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RawEDF  |  k3b.gdf, n_channels x n_times : 61 x 986780 (3947.1 sec), ~459.4 MB, data loaded>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting Data From The raw_files\n",
    "subject_list=[]\n",
    "i=0\n",
    "while True:\n",
    "    if(i == 594):\n",
    "        break\n",
    "    a=raw_files[0+i:6+i]  \n",
    "    subject_list.append(a)\n",
    "    i=i+6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw=raw_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "l_trans_bandwidth chosen to be 2.0 Hz\n",
      "h_trans_bandwidth chosen to be 7.5 Hz\n",
      "Filter length of 413 samples (1.652 sec) selected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawEDF  |  k3b.gdf, n_channels x n_times : 61 x 986780 (3947.1 sec), ~459.4 MB, data loaded>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 events found\n",
      "Events id: [ 768 1791 2323 2324 2325 2326 2337 2339 3346 3347 3348 3349 3360 3362]\n"
     ]
    }
   ],
   "source": [
    "events = find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "_, pos, kind, chan, dur = raw_files[0].find_edf_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "event_id = dict(Lhand=2323,Rhand=2324, Feet=2325,Tongue=2326)\n",
    "tmin, tmax = -1., 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 matching events found\n",
      "0 projection items activated\n",
      "Loading data for 149 events and 1251 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_train = epochs.copy().crop(tmin=1., tmax=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |  n_events : 149 (all good), tmin : 1.0 (s), tmax : 2.0 (s), baseline : None, ~17.2 MB, data loaded,\n",
       " 'Feet': 38, 'Lhand': 36, 'Rhand': 37, 'Tongue': 38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 3, 3, 3, 2, 4, 4, 1, 2, 2, 1, 2, 4, 1, 2, 3, 1, 1, 3, 1, 3, 1,\n",
       "       1, 1, 2, 4, 3, 2, 4, 2, 2, 3, 4, 1, 2, 4, 3, 1, 4, 1, 4, 3, 1, 1, 2,\n",
       "       1, 4, 4, 2, 2, 3, 4, 1, 4, 4, 3, 1, 3, 4, 3, 3, 3, 4, 2, 4, 4, 1, 1,\n",
       "       3, 2, 4, 2, 1, 4, 2, 2, 4, 1, 2, 2, 4, 2, 3, 4, 4, 3, 3, 4, 2, 3, 2,\n",
       "       1, 3, 4, 1, 2, 1, 1, 3, 4, 3, 3, 1, 3, 4, 2, 2, 2, 4, 4, 3, 3, 4, 1,\n",
       "       3, 1, 3, 3, 1, 2, 2, 1, 1, 2, 2, 3, 4, 3, 1, 1, 2, 2, 1, 3, 3, 4, 2,\n",
       "       3, 1, 1, 2, 4, 2, 4, 4, 4, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = epochs.events[:, -1]-2322\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "epochs_data = epochs.get_data()\n",
    "epochs_data_train = epochs_train.get_data()\n",
    "cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "cv_split = cv.split(epochs_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      1.00      0.92         6\n",
      "          2       1.00      0.89      0.94         9\n",
      "          3       0.80      0.67      0.73         6\n",
      "          4       0.80      0.89      0.84         9\n",
      "\n",
      "avg / total       0.87      0.87      0.87        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         7\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       0.60      0.86      0.71         7\n",
      "          4       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.86      0.83      0.83        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.75      0.86         4\n",
      "          2       0.92      1.00      0.96        11\n",
      "          3       0.78      0.88      0.82         8\n",
      "          4       0.67      0.57      0.62         7\n",
      "\n",
      "avg / total       0.83      0.83      0.83        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.88      0.82         8\n",
      "          2       0.88      0.88      0.88         8\n",
      "          3       1.00      0.75      0.86         4\n",
      "          4       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.87      0.87      0.87        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.62      0.71         8\n",
      "          2       0.50      1.00      0.67         5\n",
      "          3       0.60      0.50      0.55         6\n",
      "          4       0.78      0.64      0.70        11\n",
      "\n",
      "avg / total       0.71      0.67      0.67        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivek Sharma\\AppData\\Local\\Programs\\Python\\Python36\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Assemble a classifier\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "csp = CSP(n_components=5, reg=None, log=True, norm_trace=False)\n",
    "clf = Pipeline([('CSP', csp), ('LDA', LDA)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1, scoring=make_scorer(classification_report_with_accuracy_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.813333 / Chance level: 0.744966\n"
     ]
    }
   ],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      1.00      0.92         6\n",
      "          2       1.00      0.89      0.94         9\n",
      "          3       0.80      0.67      0.73         6\n",
      "          4       0.80      0.89      0.84         9\n",
      "\n",
      "avg / total       0.87      0.87      0.87        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         7\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       0.60      0.86      0.71         7\n",
      "          4       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.86      0.83      0.83        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.75      0.86         4\n",
      "          2       0.92      1.00      0.96        11\n",
      "          3       0.78      0.88      0.82         8\n",
      "          4       0.67      0.57      0.62         7\n",
      "\n",
      "avg / total       0.83      0.83      0.83        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.88      0.82         8\n",
      "          2       0.88      0.88      0.88         8\n",
      "          3       1.00      0.75      0.86         4\n",
      "          4       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.87      0.87      0.87        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.62      0.71         8\n",
      "          2       0.50      1.00      0.67         5\n",
      "          3       0.60      0.50      0.55         6\n",
      "          4       0.78      0.64      0.70        11\n",
      "\n",
      "avg / total       0.71      0.67      0.67        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivek Sharma\\AppData\\Local\\Programs\\Python\\Python36\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "csp = CSP(n_components=5, reg=None, log=True, norm_trace=False)\n",
    "clf = Pipeline([('CSP', csp), ('LDA', LDA)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.813333 / Chance level: 0.744966\n"
     ]
    }
   ],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "lda=(np.mean(scores))*100\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.333333333333343"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      1.00      0.80         6\n",
      "          2       1.00      0.67      0.80         9\n",
      "          3       0.67      0.67      0.67         6\n",
      "          4       0.78      0.78      0.78         9\n",
      "\n",
      "avg / total       0.80      0.77      0.77        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.86      0.92         7\n",
      "          2       0.86      1.00      0.92         6\n",
      "          3       0.60      0.86      0.71         7\n",
      "          4       0.86      0.60      0.71        10\n",
      "\n",
      "avg / total       0.83      0.80      0.80        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      1.00      0.80         4\n",
      "          2       0.91      0.91      0.91        11\n",
      "          3       0.70      0.88      0.78         8\n",
      "          4       0.67      0.29      0.40         7\n",
      "\n",
      "avg / total       0.76      0.77      0.74        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      1.00      0.84         8\n",
      "          2       1.00      0.75      0.86         8\n",
      "          3       0.75      0.75      0.75         4\n",
      "          4       0.89      0.80      0.84        10\n",
      "\n",
      "avg / total       0.86      0.83      0.83        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.75      0.80         8\n",
      "          2       0.50      1.00      0.67         5\n",
      "          3       0.80      0.67      0.73         6\n",
      "          4       1.00      0.73      0.84        11\n",
      "\n",
      "avg / total       0.84      0.77      0.78        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN=KNeighborsClassifier(n_neighbors=2)\n",
    "clf = Pipeline([('CSP', csp), ('KNN', KNN)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.786667 / Chance level: 0.744966\n"
     ]
    }
   ],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "knn=np.mean(scores)*100\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.6666666667\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.83      0.77         6\n",
      "          2       0.89      0.89      0.89         9\n",
      "          3       0.50      0.67      0.57         6\n",
      "          4       0.67      0.44      0.53         9\n",
      "\n",
      "avg / total       0.71      0.70      0.69        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.86      0.92         7\n",
      "          2       0.86      1.00      0.92         6\n",
      "          3       0.43      0.86      0.57         7\n",
      "          4       0.67      0.20      0.31        10\n",
      "\n",
      "avg / total       0.73      0.67      0.64        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.50      0.67         4\n",
      "          2       0.50      0.09      0.15        11\n",
      "          3       0.33      0.88      0.48         8\n",
      "          4       0.60      0.43      0.50         7\n",
      "\n",
      "avg / total       0.55      0.43      0.39        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      1.00      0.89         8\n",
      "          2       0.71      0.62      0.67         8\n",
      "          3       0.80      1.00      0.89         4\n",
      "          4       0.88      0.70      0.78        10\n",
      "\n",
      "avg / total       0.80      0.80      0.79        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.75      0.80         8\n",
      "          2       0.62      1.00      0.77         5\n",
      "          3       0.23      0.50      0.32         6\n",
      "          4       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.38      0.47      0.40        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP=MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "       epsilon=1e-08, hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n",
    "clf = Pipeline([('CSP', csp), ('MLP', MLP)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1, scoring=make_scorer(classification_report_with_accuracy_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.613333 / Chance level: 0.744966\n"
     ]
    }
   ],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "mlp=np.mean(scores)*100\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.3333333333 78.6666666667 61.3333333333\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.83      0.71         6\n",
      "          2       0.86      0.67      0.75         9\n",
      "          3       1.00      0.67      0.80         6\n",
      "          4       0.82      1.00      0.90         9\n",
      "\n",
      "avg / total       0.83      0.80      0.80        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.86      0.92         7\n",
      "          2       0.86      1.00      0.92         6\n",
      "          3       0.67      0.86      0.75         7\n",
      "          4       0.88      0.70      0.78        10\n",
      "\n",
      "avg / total       0.85      0.83      0.83        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         4\n",
      "          2       0.92      1.00      0.96        11\n",
      "          3       0.70      0.88      0.78         8\n",
      "          4       0.75      0.43      0.55         7\n",
      "\n",
      "avg / total       0.83      0.83      0.82        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.88      0.78         8\n",
      "          2       0.86      0.75      0.80         8\n",
      "          3       1.00      0.75      0.86         4\n",
      "          4       0.90      0.90      0.90        10\n",
      "\n",
      "avg / total       0.85      0.83      0.84        30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.50      0.62         8\n",
      "          2       0.56      1.00      0.71         5\n",
      "          3       0.60      0.50      0.55         6\n",
      "          4       0.73      0.73      0.73        11\n",
      "\n",
      "avg / total       0.69      0.67      0.66        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "SVM=svm.SVC()\n",
    "csp = CSP(n_components=5, reg=None, log=True, norm_trace=False)\n",
    "clf = Pipeline([('CSP', csp), ('SVM', SVM)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.793333 / Chance level: 0.744966\n"
     ]
    }
   ],
   "source": [
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "svm=np.mean(scores)*100\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsubject_id=input(\"Please Enter the Subject ID From 0 - 99 For Classification:::  \")\\nsubject_id_data=subject_list[int(subject_id)]\\n\\n#Preprocessing Begin\\ntmin, tmax = -1., 4.\\nevent_id = dict(hands=2, feet=3)\\n\\n#Concatenation Of All the Files\\nraw = concatenate_raws(subject_id_data)\\n\\n#Renaming of Data Extraction Channels\\nraw.rename_channels(lambda x: x.strip(\\'.\\'))\\n\\n#Applying Band Pass Filter From 7 -30 Hz Can Be Changed when needed\\nraw.filter(7., 30., fir_design=\\'firwin\\', skip_by_annotation=\\'edge\\')\\n\\nevents = find_events(raw, shortest_event=0, stim_channel=\\'STI 014\\')\\npicks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\\'bads\\')\\n# Testing will be done with a running classifier\\nepochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)\\nepochs_train = epochs.copy().crop(tmin=1., tmax=2.)\\nlabels = epochs.events[:, -1] - 2\\n\\n#Cross Validation Function\\ndef classification_report_with_accuracy_score(y_true, y_pred):\\n    print(classification_report(y_true, y_pred))\\n    return accuracy_score(y_true, y_pred)\\n\\nscores = []\\nepochs_data = epochs.get_data()\\nepochs_data_train = epochs_train.get_data()\\ncv = ShuffleSplit(5, test_size=0.2, random_state=42)\\ncv_split = cv.split(epochs_data_train)\\n\\n# Assemble a classifier\\nLDA = LinearDiscriminantAnalysis()\\ncsp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\\nclf = Pipeline([(\\'CSP\\', csp), (\\'LDA\\', LDA)])\\nscores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1, scoring=make_scorer(classification_report_with_accuracy_score))\\n\\n\\n# Results\\nclass_balance = np.mean(labels == labels[0])\\nclass_balance = max(class_balance, 1. - class_balance)\\nprint(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\\n\\n#Plot\\ncsp.fit_transform(epochs_data, labels)\\n\\nlayout = read_layout(\\'EEG1005\\')\\ncsp.plot_patterns(epochs.info, layout=layout, ch_type=\\'eeg\\', units=\\'Patterns (AU)\\', size=1.5)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "subject_id=input(\"Please Enter the Subject ID From 0 - 99 For Classification:::  \")\n",
    "subject_id_data=subject_list[int(subject_id)]\n",
    "\n",
    "#Preprocessing Begin\n",
    "tmin, tmax = -1., 4.\n",
    "event_id = dict(hands=2, feet=3)\n",
    "\n",
    "#Concatenation Of All the Files\n",
    "raw = concatenate_raws(subject_id_data)\n",
    "\n",
    "#Renaming of Data Extraction Channels\n",
    "raw.rename_channels(lambda x: x.strip('.'))\n",
    "\n",
    "#Applying Band Pass Filter From 7 -30 Hz Can Be Changed when needed\n",
    "raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "events = find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "# Testing will be done with a running classifier\n",
    "epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)\n",
    "epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "labels = epochs.events[:, -1] - 2\n",
    "\n",
    "#Cross Validation Function\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "scores = []\n",
    "epochs_data = epochs.get_data()\n",
    "epochs_data_train = epochs_train.get_data()\n",
    "cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "cv_split = cv.split(epochs_data_train)\n",
    "\n",
    "# Assemble a classifier\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "clf = Pipeline([('CSP', csp), ('LDA', LDA)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "\n",
    "\n",
    "# Results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "\n",
    "#Plot\n",
    "csp.fit_transform(epochs_data, labels)\n",
    "\n",
    "layout = read_layout('EEG1005')\n",
    "csp.plot_patterns(epochs.info, layout=layout, ch_type='eeg', units='Patterns (AU)', size=1.5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
